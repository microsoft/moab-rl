{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import onnxruntime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sim.sim_env import MoabSim\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch an onnxruntime session to run inference on the policy\n",
    "session = onnxruntime.InferenceSession(\"outputs/rllib_model.onnx\")\n",
    "\n",
    "# Initialize the simulation environment\n",
    "sim = MoabSim(env_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_actions(logits):\n",
    "        # Define low and high values\n",
    "        low = np.array([-1, -1], dtype=np.float32)\n",
    "        high = np.array([1, 1], dtype=np.float32)\n",
    "        # Define a constant for the minimum log value to avoid numerical issues\n",
    "        MIN_LOG_VALUE = -1e7\n",
    "        # Split the logits into mean and log_std\n",
    "        means, log_stds = logits[::2], logits[1::2]\n",
    "        actions = []\n",
    "        i = 0\n",
    "        for mean, log_std in zip(means, log_stds):\n",
    "            # Clip the log_std to a reasonable range\n",
    "            log_std = max(min(log_std, -MIN_LOG_VALUE), MIN_LOG_VALUE)\n",
    "            # Compute the std from the log_std\n",
    "            std = math.exp(log_std)\n",
    "            # Create a normal distribution with the mean and std\n",
    "            normal_dist = [mean, std]\n",
    "            # Sample a value from the normal distribution\n",
    "            normal_sample = mean # use the mean for deterministic output\n",
    "            # Apply a tanh function to the normal sample\n",
    "            tanh_sample = math.tanh(normal_sample)\n",
    "            # Scale the tanh sample by the low and high bounds of the action space\n",
    "            action = low[i] + (high[i] - low[i]) * (tanh_sample + 1) / 2\n",
    "            actions.append(action)\n",
    "            i += 1\n",
    "        # Return the list of actions\n",
    "        return actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episodes\n",
    "n_episodes = 30\n",
    "logs = []\n",
    "for episode in range(n_episodes):\n",
    "    # Resets the environment\n",
    "    sim.reset()\n",
    "    # Runs the simulation while the episode is not terminated or truncated\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    step = 0\n",
    "    while not terminated and not truncated:\n",
    "        # Run inference on the observation and get the logits.\n",
    "        logits = session.run(None, {\"obs\": [sim._get_obs()], \"state_ins\": [None]})[0][0]\n",
    "        actions = logits_to_actions(logits)\n",
    "        state, reward, terminated, truncated, _ = sim.step(actions)\n",
    "        step += 1\n",
    "        # Logs\n",
    "        log = {}\n",
    "        log[\"episode\"] = episode\n",
    "        log[\"step\"] = step\n",
    "        log[\"ball_x\"] = state[0]\n",
    "        log[\"ball_y\"] = state[1]\n",
    "        log[\"ball_vel_x\"] = state[2]\n",
    "        log[\"ball_vel_y\"] = state[3]\n",
    "        log[\"input_pitch\"] = actions[0]\n",
    "        log[\"input_roll\"] = actions[1]\n",
    "        log[\"reward\"] = reward\n",
    "        log[\"terminated\"] = terminated\n",
    "        log[\"truncated\"] = truncated\n",
    "        logs.append(log)\n",
    "\n",
    "logs_df = pd.DataFrame(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns for plotting\n",
    "logs_df[\"plot_marker_size\"] = logs_df[\"step\"] ** 4 / 3e6 + 20\n",
    "logs_df[\"plot_marker_alpha\"] = logs_df[\"step\"] ** 5 / 2e10 + 0.3\n",
    "logs_df.loc[(logs_df[\"terminated\"] | logs_df[\"truncated\"]), \"plot_marker_alpha\"] = 1\n",
    "\n",
    "def generate_plot(episode_id, logs_df):\n",
    "    fig, ax = plt.subplots()\n",
    "    circle = plt.Circle((0, 0), 0.1125, color=\"lightgray\") # Create a circle object\n",
    "    ax.add_patch(circle) \n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-0.15, 0.15)\n",
    "    ax.set_ylim(-0.15, 0.15)\n",
    "    # Plot the trajectory using step, ball_x and ball_y from logs_df\n",
    "    episode_logs = logs_df.loc[logs_df[\"episode\"] == episode_id]\n",
    "    scatter = plt.scatter(episode_logs[\"ball_x\"],\n",
    "                          episode_logs[\"ball_y\"],\n",
    "                          c=episode_logs[\"reward\"],\n",
    "                          s=episode_logs[\"plot_marker_size\"],\n",
    "                          alpha=episode_logs[\"plot_marker_alpha\"],\n",
    "                          cmap=\"plasma\") \n",
    "    cbar = fig.colorbar(scatter)\n",
    "    cbar.ax.set_title(\"Reward\", fontsize=10)\n",
    "    plt.clim(0, 1)\n",
    "    # Add a line connecting the steps\n",
    "    plt.plot(episode_logs[\"ball_x\"], episode_logs[\"ball_y\"], color=\"gray\", linewidth=1)\n",
    "    # Add an arrow at the last step\n",
    "    dx, dy = episode_logs[\"ball_vel_x\"].iloc[-1], episode_logs[\"ball_vel_y\"].iloc[-1]\n",
    "    dx, dy = 0.01 * np.array([dx, dy]) / np.hypot(dx, dy)\n",
    "    plt.arrow(episode_logs[\"ball_x\"].iloc[-1], episode_logs[\"ball_y\"].iloc[-1],\n",
    "              dx, dy, head_width=0.008, length_includes_head=True,\n",
    "              head_starts_at_zero=True, color=\"black\", linewidth=0)\n",
    "    # Show the plot\n",
    "    plt.title(f\"Moab Ball Trajectory #{episode_id+1}\")\n",
    "    plt.xlabel(\"ball_x\")\n",
    "    plt.ylabel(\"ball_y\")\n",
    "    plt.close(fig)\n",
    "    fig.canvas.draw()\n",
    "    img = PIL.Image.frombytes(\"RGB\", fig.canvas.get_width_height(),fig.canvas.tostring_rgb())\n",
    "    return img\n",
    "\n",
    "imgs = [generate_plot(episode_id, logs_df) for episode_id in range(n_episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(10, 3, figsize=(18, 50))\n",
    "axs = axs.flatten()\n",
    "for img, ax in zip(imgs, axs):\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
